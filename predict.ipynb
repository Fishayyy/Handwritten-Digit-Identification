{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we bring in all of our imports and set the desired size of the image. We have chosen 28x28 as the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import itertools\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# SET THE IMAGE SIZE\n",
    "IMAGE_SIZE = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define a method to bring in all of our images from either the processed or unprocessed folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train_test, processed_unprocessed):\n",
    "  cwd = os.getcwd()\n",
    "  data = []\n",
    "\n",
    "  path = os.path.realpath(f'processed_images/{train_test}/{processed_unprocessed}/')\n",
    "  for filename in os.listdir(path):\n",
    "      #Read in Image\n",
    "      filepath = f\"{path}/{filename}\"\n",
    "\n",
    "      img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "      #Resize Image\n",
    "      desired_size = IMAGE_SIZE\n",
    "      old_size = img.shape[:2] \n",
    "\n",
    "      ratio = float(desired_size)/max(old_size)\n",
    "      new_size = tuple([int(x*ratio) for x in old_size])\n",
    "\n",
    "      img = cv2.resize(img, (new_size[1], new_size[0]))\n",
    "\n",
    "      delta_w = desired_size - new_size[1]\n",
    "      delta_h = desired_size - new_size[0]\n",
    "      top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "      left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "\n",
    "      color = [255, 255, 255]\n",
    "      img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "\n",
    "      data.append([img, filename[0]])\n",
    "\n",
    "  return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we ask the user which dataset they would like to load in. The set processed into a binarized image, or the grayscale unprocessed version of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which dataset would you like to train on?\n",
      "'binary'/'grayscale'?:grayscale\n"
     ]
    }
   ],
   "source": [
    "choices = [\"binary\", \"grayscale\"]\n",
    "user_input = \"\"\n",
    "\n",
    "print(\"Which dataset would you like to train on?\")\n",
    "while user_input not in choices:\n",
    "  user_input = input(\"\\'binary\\'/\\'grayscale\\'?:\")\n",
    "\n",
    "train_data = get_data(\"train\", user_input)\n",
    "test_data = get_data(\"test\", user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our data loaded into memory we proceed to split the data into its training and test sets and append all of the class labels to the corresponding images. Since our dataset is small we have chosen to use a validation set that is only 5% of our training data. We also stratify the split to ensure an equal distribution of class labels in our validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "for feature, label in train_data:\n",
    "  X_train.append(feature)\n",
    "  Y_train.append(label)\n",
    "\n",
    "for feature, label in test_data:\n",
    "  X_test.append(feature)\n",
    "  Y_test.append(label)\n",
    "\n",
    "# Normalize the data\n",
    "X_train = np.array(X_train) / 255.0\n",
    "X_test = np.array(X_test) / 255.0\n",
    "\n",
    "X_train = X_train.reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 1)\n",
    "X_test = X_test.reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 1)\n",
    "Y_train = to_categorical(Y_train, num_classes = 10)\n",
    "Y_test = to_categorical(Y_test, num_classes= 10)\n",
    "\n",
    "# Split the train and the validation set for the fitting\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, stratify=Y_train, test_size = 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we build out our CNN model, compile it and print out a summary of its layers for visualization purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 887,530\n",
      "Trainable params: 887,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (IMAGE_SIZE,IMAGE_SIZE,1)))\n",
    "model.add(layers.Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu'))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
    "model.add(layers.Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation = \"relu\"))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation = \"softmax\"))\n",
    "\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(optimizer=optimizer , loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we perform our final setps before handing off all the data to our model for training. We choose to set the epochs to 64 and the batch size to 12, but these can be adjusted and played with. Since our dataset was relatively small we decided to bolster the dataset using image augmentations. We also added a learning rate annealer to help prevent overfitting and end training early if it isn't seeing an imrovement in our loss per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 64 \n",
    "batch_size = 12\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='accuracy', patience=3, verbose=1, factor=0.5, min_lr=0.00001)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=12,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1)  # randomly shift images vertically (fraction of total height)\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we fit our model using our ImageDataGenerator, learning rate annealer, and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.3146 - accuracy: 0.1057 - val_loss: 2.3026 - val_accuracy: 0.0943\n",
      "Epoch 2/64\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.3050 - accuracy: 0.1051 - val_loss: 2.2959 - val_accuracy: 0.1321\n",
      "Epoch 3/64\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.2006 - accuracy: 0.1849 - val_loss: 1.3259 - val_accuracy: 0.5849\n",
      "Epoch 4/64\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.6464 - accuracy: 0.4638 - val_loss: 1.3092 - val_accuracy: 0.5472\n",
      "Epoch 5/64\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.4753 - accuracy: 0.5087 - val_loss: 0.7924 - val_accuracy: 0.7358\n",
      "Epoch 6/64\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.1617 - accuracy: 0.6078 - val_loss: 0.7332 - val_accuracy: 0.8302\n",
      "Epoch 7/64\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0738 - accuracy: 0.6209 - val_loss: 0.5848 - val_accuracy: 0.8491\n",
      "Epoch 8/64\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.9577 - accuracy: 0.6975 - val_loss: 0.4008 - val_accuracy: 0.8868\n",
      "Epoch 9/64\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.7945 - accuracy: 0.7537 - val_loss: 0.3048 - val_accuracy: 0.9057\n",
      "Epoch 10/64\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.7630 - accuracy: 0.7650 - val_loss: 0.3106 - val_accuracy: 0.8679\n",
      "Epoch 11/64\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6390 - accuracy: 0.8115 - val_loss: 0.3251 - val_accuracy: 0.8679\n",
      "Epoch 12/64\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6106 - accuracy: 0.7951 - val_loss: 0.2562 - val_accuracy: 0.9245\n",
      "Epoch 13/64\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5562 - accuracy: 0.8176 - val_loss: 0.2511 - val_accuracy: 0.9057\n",
      "Epoch 14/64\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4991 - accuracy: 0.8334 - val_loss: 0.2714 - val_accuracy: 0.9245\n",
      "Epoch 15/64\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4623 - accuracy: 0.8494 - val_loss: 0.2208 - val_accuracy: 0.9434\n",
      "Epoch 16/64\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6015 - accuracy: 0.8142 - val_loss: 0.1914 - val_accuracy: 0.9434\n",
      "Epoch 17/64\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4164 - accuracy: 0.8615 - val_loss: 0.2261 - val_accuracy: 0.9434\n",
      "Epoch 18/64\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4012 - accuracy: 0.8662 - val_loss: 0.1508 - val_accuracy: 0.9434\n",
      "Epoch 19/64\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.3816 - accuracy: 0.8823 - val_loss: 0.1668 - val_accuracy: 0.9434\n",
      "Epoch 20/64\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4252 - accuracy: 0.8764 - val_loss: 0.1826 - val_accuracy: 0.9623\n",
      "Epoch 21/64\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.3347 - accuracy: 0.8912 - val_loss: 0.0950 - val_accuracy: 0.9811\n",
      "Epoch 22/64\n",
      "20/83 [======>.......................] - ETA: 0s - loss: 0.4846 - accuracy: 0.8512"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                              validation_data = (X_val, Y_val),\n",
    "                              epochs = epochs, \n",
    "                              steps_per_epoch=X_train.shape[0] // batch_size, \n",
    "                              callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then plot out some metrics recorded from our traing to ensure that our ROC looks appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "print(history.history.keys())\n",
    "\n",
    "ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can test our trained model on the test set and create a classification matrix so that we can visualize our results a little better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(X_test)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(Y_test,axis = 1) \n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(10)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also print out a classification report so that we can see how our model performed on making classifications for each class based on a set of statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(Y_true, Y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can print out our top 4 misclassified labels to better visualize why they were mistaken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = (Y_pred_classes - Y_true != 0)\n",
    "\n",
    "Y_pred_classes_errors = Y_pred_classes[errors]\n",
    "Y_pred_errors = Y_pred[errors]\n",
    "Y_true_errors = Y_true[errors]\n",
    "X_test_errors = X_test[errors]\n",
    "\n",
    "def display_errors(errors_index,img_errors,pred_errors, obs_errors):\n",
    "    n = 0\n",
    "    nrows = 2\n",
    "    ncols = 2\n",
    "    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n",
    "    fig.set_figheight(10)\n",
    "    fig.set_figwidth(10)\n",
    "    for row in range(nrows):\n",
    "        for col in range(ncols):\n",
    "            error = errors_index[n]\n",
    "            ax[row,col].imshow((img_errors[error]).reshape((IMAGE_SIZE,IMAGE_SIZE)))\n",
    "            ax[row,col].set_title(f\" Predicted label :{pred_errors[error]}\\nTrue label :{obs_errors[error]}\")\n",
    "            n += 1\n",
    "\n",
    "# Probabilities of the wrong predicted numbers\n",
    "Y_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n",
    "\n",
    "# Predicted probabilities of the true values in the error set\n",
    "true_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n",
    "\n",
    "# Difference between the probability of the predicted label and the true label\n",
    "delta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n",
    "\n",
    "# Sorted list of the delta prob errors\n",
    "sorted_dela_errors = np.argsort(delta_pred_true_errors)\n",
    "\n",
    "# Top 4 errors \n",
    "most_important_errors = sorted_dela_errors[-4:]\n",
    "\n",
    "# Show the top 4 errors\n",
    "display_errors(most_important_errors, X_test_errors, Y_pred_classes_errors, Y_true_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
